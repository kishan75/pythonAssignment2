{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pythonAssignment2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzLbZEGQNehGOJUgyCQmJA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kishan75/pythonAssignment2/blob/main/pythonAssignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHYKu2oOUq27"
      },
      "source": [
        "1. **Write a program in python to read the three file N1, N2, N3. Each of the files contains list of names. Following operations must be performed by the program:**\n",
        "\n",
        "a.   The program should display the contents of each file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zouw9v7WnVm",
        "outputId": "e0bb4e9f-a2bc-4cf1-ba39-ee62d9dbfbcc"
      },
      "source": [
        "with open('N1.txt','r') as file_N1:\n",
        "  read_data = file_N1.read()\n",
        "  print(read_data)\n",
        "  global file_1_data\n",
        "  file_1_data = read_data.splitlines()\n",
        "\n",
        "with open('N2.txt','r') as file_N2:\n",
        "  read_data = file_N2.read()\n",
        "  print(read_data)\n",
        "  global file_2_data\n",
        "  file_2_data = read_data.splitlines()\n",
        "\n",
        "with open('N3.txt','r') as file_N3:\n",
        "  read_data = file_N3.read()\n",
        "  print(read_data)\n",
        "  global file_3_data\n",
        "  file_3_data = read_data.splitlines()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rajinkant\n",
            "Will Smith\n",
            "Akshay\n",
            "Emraan\n",
            "Aamir\n",
            "Katrina\n",
            "Ajay\n",
            "Leonardo DiCaprio\n",
            "Sanjay\n",
            "Lindsay Lohan\n",
            "Hrithik\n",
            "Tiger\n",
            "Deepika\n",
            "Alia\n",
            "Shahrukh\n",
            "Om Puri\n",
            "Kiara\n",
            "Ranbeer\n",
            "Ranveer\n",
            "Nana Patekar\n",
            "Manoj Tiwari\n",
            "Jackie Shroff\n",
            "Emma Watson\n",
            "\n",
            "\n",
            "Will Smith\n",
            "Robert\n",
            "Shashank\n",
            "Lauren\n",
            "Emraan\n",
            "William\n",
            "Tim\n",
            "Scott\n",
            "Sam\n",
            "Leonardo DiCaprio\n",
            "Rowling\n",
            "Prateik Babbar\n",
            "Lindsay Lohan\n",
            "Deepika\n",
            "Dharmendra\n",
            "Om Puri\n",
            "Dev Anand\n",
            "Nana Patekar\n",
            "Ali Fazal\n",
            "Emma Watson\n",
            "\n",
            "Neil Nitin Mukesh\n",
            "Rahul Roy\n",
            "Varun Dhawan\n",
            "Vinay Pathak\n",
            "Will Smith\n",
            "Richa Chadda\n",
            "Anushka Sharma\n",
            "Vaani Kapoor\n",
            "Emraan\n",
            "Leonardo DiCaprio\n",
            "Lindsay Lohan\n",
            "Shraddha Kapoor\n",
            "Deepika\n",
            "Om Puri\n",
            "Kangana Ranaut\n",
            "Nana Patekar\n",
            "Hansika Motwani\n",
            "Vidya Balan\n",
            "Emma Watson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn4mThjmZ-Ua"
      },
      "source": [
        "b.   Display the names that are common in all three files in the order in which they appear in the file and store them in output file \"output.txt\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRwUSVQ9aAEw",
        "outputId": "b8c5c5fa-461e-4d7d-9f7d-cf442a726e63"
      },
      "source": [
        "output_file_data = []\n",
        "\n",
        "with open('output.txt','a') as file_output:\n",
        "  for name in file_1_data:\n",
        "    if name in file_2_data and name in file_3_data:\n",
        "      file_output.write(name+'\\n')\n",
        "      output_file_data.append(name)\n",
        "\n",
        "print(output_file_data)\n",
        "\n",
        "with open('output.txt','r') as file_data:\n",
        "  read_data = file_data.read()\n",
        "  print(read_data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Will Smith', 'Emraan', 'Leonardo DiCaprio', 'Lindsay Lohan', 'Deepika', 'Om Puri', 'Nana Patekar', 'Emma Watson']\n",
            "Will Smith\n",
            "Emraan\n",
            "Leonardo DiCaprio\n",
            "Lindsay Lohan\n",
            "Deepika\n",
            "Om Puri\n",
            "Nana Patekar\n",
            "Emma Watson\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il7nbY31aAl1"
      },
      "source": [
        "c. Read all the names from output file \"output.txt\" and form word using first character of all the names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jDudwUNz9vX",
        "outputId": "cb14d558-5a64-47af-928f-a4f181cd9a17"
      },
      "source": [
        "with open('output.txt','r') as file_data:\n",
        "  read_data = file_data.read()\n",
        "  print(''.join([word[0] for word in read_data.splitlines()]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WELLDONE\n"
          ]
        }
      ]
    }
  ]
}